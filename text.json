[
  {
    "id": 1,
    "name": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift",
    "link": "https://arxiv.org/pdf/1502.03167",
    "text": "Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization. It also acts as a regularizer, in some cases eliminating the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.9% top-5 validation error (and 4.8% test error), exceeding the accuracy of human raters."
  },
  {
    "id": 2,
    "name": "REVISITING SMALL BATCH TRAINING FOR DEEP NEURAL NETWORKS",
    "link": "https://arxiv.org/pdf/1804.07612",
    "text": "Modern deep neural network training is typically based on mini-batch stochastic gradient optimization. While the use of large mini-batches increases the available computational parallelism, small batch training has been shown to provide improved generalization performance and allows a significantly smaller memory footprint, which might also be exploited to improve machine throughput. In this paper, we review common assumptions on learning rate scaling and training duration, as a basis for an experimental comparison of test performance for different mini-batch sizes. We adopt a learning rate that corresponds to a constant average weight update per gradient calculation (i.e., per unit cost of computation), and point out that this results in a variance of the weight updates that increases linearly with the mini-batch size m. The collected experimental results for the CIFAR-10, CIFAR-100 and ImageNet datasets show that increasing the mini-batch size progressively reduces the range of learning rates that provide stable convergence and acceptable test performance. On the other hand, small mini-batch sizes provide more up-to-date gradient calculations, which yields more stable and reliable training. The best performance has been consistently obtained for mini-batch sizes between m = 2 and m = 32, which contrasts with recent work advocating the use of mini-batch sizes in the thousands."
  },
  {
    "id": 3,
    "name": "Train longer, generalize better: closing the generalization gap in large batch training of neural networks",
    "link": "https://arxiv.org/pdf/1705.08741",
    "text": "Background: Deep learning models are typically trained using stochastic gradient descent or one of its variants. These methods update the weights using their gradient, estimated from a small fraction of the training data. It has been observed that when using large batch sizes there is a persistent degradation in generalization performance - known as the generalization gap phenomenon. Identifying the origin of this gap and closing it had remained an open problem. Contributions: We examine the initial high learning rate training phase. We find that the weight distance from its initialization grows logarithmically with the number of weight updates. We therefore propose a random walk on a random landscape statistical model which is known to exhibit similar ultra-slow diffusion behavior. Following this hypothesis we conducted experiments to show empirically that the generalization gap stems from the relatively small number of updates rather than the batch size, and can be completely eliminated by adapting the training regime used. We further investigate different techniques to train models in the large-batch regime and present a novel algorithm named Ghost Batch Normalization which enables significant decrease in the generalization gap without increasing the number of updates. To validate our findings we conduct several additional experiments on MNIST, CIFAR-10, CIFAR-100 and ImageNet. Finally, we reassess common practices and beliefs concerning training of deep models and suggest they may not be optimal to achieve good generalization."
  },
  {
    "id": 4,
    "name": "Segment Anything Across Shots: A Method and Benchmark",
    "link": "https://arxiv.org/pdf/2511.13715",
    "text": "This work focuses on multi-shot semi-supervised video object segmentation (MVOS), which aims at segmenting the target object indicated by an initial mask throughout a video with multiple shots. The existing VOS methods mainly focus on single-shot videos and struggle with shot discontinuities, thereby limiting their real-world applicability. We propose a transition mimicking data augmentation strategy (TMA) which enables cross-shot generalization with single-shot data to alleviate the severe annotated multi-shot data sparsity, and the Segment Anything Across Shots (SAAS) model, which can detect and comprehend shot transitions effectively. To support evaluation and future study in MVOS, we introduce Cut-VOS, a new MVOS benchmark with dense mask annotations, diverse object categories, and high-frequency transitions. Extensive experiments on YouMVOS and Cut-VOS demonstrate that the proposed SAAS achieves state-of-the-art performance by effectively mimicking, understanding, and segmenting across complex transitions."
  },
  {
    "id": 5,
    "name": "Referring Camouflaged Object Detection With Multi-Context Overlapped Windows Cross-Attention",
    "link": "https://arxiv.org/pdf/2511.13249",
    "text": "Referring camouflaged object detection (Ref-COD) aims to identify hidden objects by incorporating reference information such as images and text descriptions. Previous research has transformed reference images with salient objects into one-dimensional prompts, yielding significant results. We explore ways to enhance performance through multi-context fusion of rich salient image features and camouflaged object features. Therefore, we propose RFMNet, which utilizes features from multiple encoding stages of the reference salient images and performs interactive fusion with the camouflage features at the corresponding encoding stages. Given that the features in salient object images contain abundant object-related detail information, performing feature fusion within local areas is more beneficial for detecting camouflaged objects. Therefore, we propose an Overlapped Windows Cross-attention mechanism to enable the model to focus more attention on the local information matching based on reference features. Besides, we propose the Referring Feature Aggregation (RFA) module to decode and segment the camouflaged objects progressively. Extensive experiments on the Ref-COD benchmark demonstrate that our method achieves state-of-the-art performance."
  },
  {
    "id": 6,
    "name": "Self-Supervised Learning to Fly using Efficient Semantic Segmentation and Metric Depth Estimation for Low-Cost Autonomous UAVs",
    "link": "https://arxiv.org/pdf/2510.16624",
    "text": "This paper presents a vision-only autonomous flight system for small UAVs operating in controlled indoor environments. The system combines semantic segmentation with monocular depth estimation to enable obstacle avoidance, scene exploration, and autonomous safe landing operations without requiring GPS or expensive sensors such as LiDAR. A key innovation is an adaptive scale factor algorithm that converts non-metric monocular depth predictions into accurate metric distance measurements by leveraging semantic ground plane detection and camera intrinsic parameters, achieving a mean distance error of 14.4 cm. The approach uses a knowledge distillation framework where a color-based Support Vector Machine (SVM) teacher generates training data for a lightweight U-Net student network (1.6M parameters) capable of real-time semantic segmentation. For more complex environments, the SVM teacher can be replaced with a state-of-the-art segmentation model. Testing was conducted in a controlled 5x4 meter laboratory environment with eight cardboard obstacles simulating urban structures. Extensive validation across 30 flight tests in a real-world environment and 100 flight tests in a digital-twin environment demonstrates that the combined segmentation and depth approach increases the distance traveled during surveillance and reduces mission time while maintaining 100% success rates. The system is further optimized through end-to-end learning, where a compact student neural network learns complete flight policies from demonstration data generated by our best-performing method, achieving an 87.5% autonomous mission success rate. This work advances practical vision-based drone navigation in structured environments, demonstrating solutions for metric depth estimation and computational efficiency challenges that enable deployment on resource-constrained platforms."
  },
  {
    "id": 7,
    "name": "Handover-Aware URLLC UAV Trajectory Planning: A Continuous-Time Trajectory Optimization via Graphs of Convex Sets",
    "link": "https://arxiv.org/pdf/2511.13429",
    "text": "In this paper, we study a cellular-connected unmanned aerial vehicle (UAV) which aims to fly between two predetermined locations while maintaining ultra-reliable low-latency communications (URLLC) for command-and-control (C2) links with terrestrial base stations (BSs). Long-range flights often trigger frequent inter-cell handovers, which may introduce delays and synchronization overhead. We jointly optimize the continuous trajectory and BS association to minimize handovers, path length, and flying time, subject to communication reliability and kinematic constraints. To address this problem, we reformulate it as an optimization based on the graph of convex sets (GCS). First, the URLLC requirement is translated into spatially feasible regions in the flight plane for each BS. An intersection graph is constructed including the start and goal points. Each graph node is associated with a smooth and dynamically feasible trajectory segment. The trajectory is parameterized in space by Bezier curves and in time by a monotonic Bezier scaling, together with convex constraints that ensure continuity and enforce speed bounds. Next, we impose unit-flow constraints to enforce a single path, and by coupling the resulting binary edge-selection variables with the convex constraints, we obtain a mixed-integer convex program (MICP). Applying a convex relaxation and rounding to the mixed-integer convex program produces nearly globally optimal routes, and a final refinement yields smooth, dynamically feasible trajectories. Simulations verify that the method preserves URLLC connectivity while achieving a clear trade-off between fewer handovers and flight efficiency."
  },
  {
    "id": 8,
    "name": "A Co-simulation Framework for Quadrotor Control System Design using ROS 2 and MATLAB/Simulink",
    "link": "https://arxiv.org/pdf/2511.03969",
    "text": "Co-simulation is a critical approach for the design and analysis of complex cyber-physical systems. It enhances development efficiency and reduces costs. This paper presents a co-simulation framework integrating ROS 2 and MATLAB/Simulink for quadrotor unmanned aerial vehicle (UAV) control system design and verification. First, a six-degree-of-freedom nonlinear dynamic model of the quadrotor is derived accurately based on Newton-Euler equations. Second, within the proposed framework, a hierarchical control architecture was designed and implemented: LQR controller for attitude control to achieve optimal regulation performance, and PID controller for position control to ensure robustness and practical applicability. Third, the architecture of the framework is elaborated, including the implementation details of the cross-platform data exchange mechanism. Simulation results demonstrate the effectiveness of the framework, highlighting its capability to provide an efficient and standardized solution for rapid prototyping and Software-in-the-Loop (SIL) validation of UAV control algorithms."
  },
  {
    "id": 9,
    "name": "PyTorch: CUDA semantics",
    "link": "https://docs.pytorch.org/docs/stable/notes/cuda.html#cuda-semantics",
    "text": "torch.cuda is used to set up and run CUDA operations. It keeps track of the currently selected GPU, and all CUDA tensors you allocate will by default be created on that device. The selected device can be changed with a torch.cuda.device context manager. However, once a tensor is allocated, you can do operations on it irrespective of the selected device, and the results will be always placed on the same device as the tensor. Cross-GPU operations are not allowed by default, with the exception of copy_() and other methods with copy-like functionality such as to() and cuda(). Unless you enable peer-to-peer memory access, any attempts to launch ops on tensors spread across different devices will raise an error."
  },
  {
    "id": 10,
    "name": "Asynchronous multiprocess training (e.g. Hogwild)",
    "link": "https://docs.pytorch.org/docs/stable/notes/multiprocessing.html#asynchronous-multiprocess-training-e-g-hogwild",
    "text": "Using torch.multiprocessing, it is possible to train a model asynchronously, with parameters either shared all the time, or being periodically synchronized. In the first case, we recommend sending over the whole model object, while in the latter, we advise to only send the state_dict(). We recommend using multiprocessing.Queue for passing all kinds of PyTorch objects between processes. It is possible to e.g. inherit the tensors and storages already in shared memory, when using the fork start method, however it is very bug prone and should be used with care, and only by advanced users. Queues, even though they're sometimes a less elegant solution, will work properly in all cases."
  }
]